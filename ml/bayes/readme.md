**贝叶斯：**    
 使用概率分布进行分类，属于生成模式
 

**朴素贝叶斯：** 
	先验概率+数据=后验概率
	  
	**贝叶斯公式：**
	P(Y|X)=P(X|Y)P(Y)/P(X)
	
	有m个样本，每个样本有n个特征，特征输出有K个类别，定义为C1,C2,...,CK。
	
	**朴素贝叶斯假设：**
	1、各特征之间相互独立
	2、每个特征同等重要
	
	
	先验分布：P(Y=Ck)(k=1,2,...K)  （可从样本中学得，可假设）
	条件概率分布：P(X=x|Y=Ck)=P(X1=x1,X2=x2,...Xn=xn|Y=Ck)， 从训练样本中学得
	X和Y的联合分布P(X,Y)：P(X,Y=Ck)=P(Y=Ck)P(X=x|Y=Ck)=P(X1=x1|Y=Ck)P(X2=x2|Y=Ck)...P(Xn=xn|Y=Ck)
	P(X)=∑P(X|Y=Yk)P(Yk)
	
	存在问题：
	1、可能有特征值未出现，P(Xn=xn|Y=Ck)=0; 解决方法：拉普拉斯平滑
	2、特征太稀疏，出现下溢情况；解决方法：概率值取对数
	
 

**朴素贝叶斯优缺点：**    
 优点：有稳定的分类效率，适合增量式训练，对缺失数据不太敏感，算法也比较简单     
 缺点：需要知道先验概率，而先验概率大多取决于假设；对输入数据的表达形式很敏感

**来源：** 机器学习实战(第四章)   
https://github.com/pbharrin/machinelearninginaction
